{"cells":[{"cell_type":"markdown","id":"71461c33","metadata":{"id":"71461c33"},"source":["# Section 3.2 LightGBM with Bayesian Optimisation"]},{"cell_type":"code","execution_count":null,"id":"f46c383b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27013,"status":"ok","timestamp":1660921880455,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"f46c383b","outputId":"b8931196-1999-43f8-d042-4ffdec8c845f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# 把Google Drive挂载到Colab里\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except ImportError:\n","    pass"]},{"cell_type":"code","execution_count":null,"id":"77WxSYIi-kJw","metadata":{"id":"77WxSYIi-kJw"},"outputs":[],"source":["# 修改当前文件夹位置 假定notebook文件就在项目文件夹根目录\n","import os\n","def get_root_dir():\n","    if os.path.exists('/content/drive/MyDrive/Colab/'):\n","        return '/content/drive/MyDrive/Colab/4-AMEX/AMEX Project/notebooks' #在Colab里\n","    else:\n","        return './' #在本地\n","\n","#调用系统命令，相当于cd，但是直接!cd是不行的\n","os.chdir(get_root_dir())"]},{"cell_type":"code","execution_count":null,"id":"-ehcNroMM7ny","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":6764,"status":"ok","timestamp":1660921889235,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"-ehcNroMM7ny","outputId":"7ddf36f5-8fce-42c5-f2f8-9b9915ebfaaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lightgbm==3.1.1\n","  Downloading lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (0.37.1)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (1.1.0)\n","Installing collected packages: lightgbm\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","Successfully installed lightgbm-3.1.1\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.1.1'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["!pip install lightgbm==3.1.1\n","import lightgbm as lgb\n","lgb.__version__"]},{"cell_type":"code","execution_count":null,"id":"N_rEwa1kGuQf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":5462,"status":"ok","timestamp":1660921894691,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"N_rEwa1kGuQf","outputId":"ffda1e03-e526-482b-9689-38b9d21897eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hyperopt==0.2.7\n","  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.3 MB/s \n","\u001b[?25hCollecting py4j\n","  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","\u001b[K     |████████████████████████████████| 200 kB 73.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (1.15.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (1.3.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (2.6.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (4.64.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.7) (0.16.0)\n","Installing collected packages: py4j, hyperopt\n","  Attempting uninstall: hyperopt\n","    Found existing installation: hyperopt 0.1.2\n","    Uninstalling hyperopt-0.1.2:\n","      Successfully uninstalled hyperopt-0.1.2\n","Successfully installed hyperopt-0.2.7 py4j-0.10.9.7\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.2.7'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["!pip install hyperopt==0.2.7\n","import hyperopt\n","hyperopt.__version__"]},{"cell_type":"code","execution_count":null,"id":"ab7e16a6","metadata":{"id":"ab7e16a6"},"outputs":[],"source":["import time\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"a4a591fd","metadata":{"id":"a4a591fd"},"outputs":[],"source":["from numpy.random import RandomState"]},{"cell_type":"code","execution_count":null,"id":"d46afd5f","metadata":{"id":"d46afd5f"},"outputs":[],"source":["import lightgbm as lgb\n","from hyperopt import hp, fmin, tpe\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":null,"id":"fc3a0351-6f36-40dc-9f73-cd9015864f8b","metadata":{"id":"fc3a0351-6f36-40dc-9f73-cd9015864f8b"},"outputs":[],"source":["from hyperopt import hp, fmin, tpe\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval"]},{"cell_type":"code","execution_count":null,"id":"fd7e5475","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660921894692,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"fd7e5475","outputId":"83bee7ef-43a7-4999-90e0-db4a95569ebf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.2.7'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import hyperopt\n","hyperopt.__version__"]},{"cell_type":"markdown","id":"df17a8d8-d2e0-4f68-863c-308e6ca7d23a","metadata":{"id":"df17a8d8-d2e0-4f68-863c-308e6ca7d23a"},"source":["其中hp是参数空间创建函数，fmin是参数搜索函数，tpe则是一种基于贝叶斯过程的搜索策略。"]},{"cell_type":"markdown","id":"9d310104","metadata":{"id":"9d310104"},"source":["## 导入数据"]},{"cell_type":"markdown","id":"5fd4b09d","metadata":{"id":"5fd4b09d"},"source":["我们使用的数据是压缩之后的最终数据：Part I + Part II + Part III\n","\n","保证一行对应一个唯一客户。"]},{"cell_type":"code","execution_count":null,"id":"21a2ac2f-fb5d-4465-9641-ba7e7d0bfaeb","metadata":{"id":"21a2ac2f-fb5d-4465-9641-ba7e7d0bfaeb"},"outputs":[],"source":["train_LGBM = pd.read_parquet(\"../data/2-processed-demo/train_fe.parquet\")\n","test_LGBM = pd.read_parquet(\"../data/2-processed-demo/test_fe.parquet\")"]},{"cell_type":"code","execution_count":null,"id":"6e937669-3971-44b5-ab12-c8ec9a02ee6f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1660921946416,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"6e937669-3971-44b5-ab12-c8ec9a02ee6f","outputId":"4f7f914f-8593-4863-8a39-341cb2d08476"},"outputs":[{"data":{"text/plain":["(458913, 920)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train_LGBM.shape"]},{"cell_type":"code","execution_count":null,"id":"182cdaee","metadata":{"id":"182cdaee"},"outputs":[],"source":["train_LGBM = train_LGBM.fillna(0)\n","test_LGBM = test_LGBM.fillna(0)"]},{"cell_type":"markdown","id":"69d8f75f","metadata":{"id":"69d8f75f"},"source":["## Metric"]},{"cell_type":"code","execution_count":null,"id":"be713276","metadata":{"id":"be713276"},"outputs":[],"source":["def amex_metric(y_true, y_pred):\n","    labels = np.transpose(np.array([y_true, y_pred]))\n","    labels = labels[labels[:, 1].argsort()[::-1]]\n","    weights = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n","    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels = np.transpose(np.array([y_true, y_pred]))\n","        labels = labels[labels[:, i].argsort()[::-1]]\n","        weight = np.where(labels[:,0]==0, 20, 1)\n","        weight_random = np.cumsum(weight / np.sum(weight))\n","        total_pos = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n","        lorentz = cum_pos_found / total_pos\n","        gini[i] = np.sum((lorentz - weight_random) * weight)\n","    return 0.5 * (gini[1]/gini[0] + top_four)"]},{"cell_type":"code","execution_count":null,"id":"5aaa59c6","metadata":{"id":"5aaa59c6"},"outputs":[],"source":["def lgb_amex_metric(y_pred, y_true):\n","    y_true = y_true.get_label()\n","    return 'AMEX_metric', amex_metric(y_true, y_pred), True"]},{"cell_type":"markdown","id":"b9bc9e12-18d6-4eaf-9e08-22a1e3745cb0","metadata":{"id":"b9bc9e12-18d6-4eaf-9e08-22a1e3745cb0"},"source":["## 贝叶斯优化"]},{"cell_type":"markdown","id":"ea898113-91ec-4d1f-8cc6-1714b4fd006d","metadata":{"id":"ea898113-91ec-4d1f-8cc6-1714b4fd006d"},"source":["### 参数回调函数"]},{"cell_type":"markdown","id":"0597a8fa-35fd-42b5-bc94-dc4130f1a915","metadata":{"id":"0597a8fa-35fd-42b5-bc94-dc4130f1a915"},"source":["对于lgb模型来说，并不是所有的超参数都需要进行搜索。\n","\n","为了防止多次实例化模型过程中部分超参数被设置成默认参数，我们首先需要创建一个参数回调函数，用于在后续多次实例化模型过程中反复申明这部分参数的固定取值："]},{"cell_type":"code","execution_count":null,"id":"1cf8503b-3f9c-440d-a30a-90a956b3fa12","metadata":{"id":"1cf8503b-3f9c-440d-a30a-90a956b3fa12"},"outputs":[],"source":["def params_append(params):\n","    \"\"\"\n","    动态回调参数函数，params视作字典\n","    :param params:lgb参数字典\n","    :return params:修正后的lgb参数字典\n","    \"\"\"\n","    params['feature_pre_filter'] = False\n","    params['objective'] = \"binary\"\n","    params['metric'] = \"None\" # 将用自定义metric（feval中声明）\n","    params[\"is_unbalance\"] = True # 不平衡数据\n","    params[\"boosting\"] = \"dart\" # gbdt, rf, dart\n","    params[\"verbose\"] = 1\n","\n","    return params"]},{"cell_type":"markdown","id":"38198834-3eb4-4561-b3c6-464b541dd6b0","metadata":{"id":"38198834-3eb4-4561-b3c6-464b541dd6b0"},"source":["### 寻找最优超参数"]},{"cell_type":"code","execution_count":null,"id":"102ef0a9-ce3e-4c75-a6e2-dfa02b3cc5e4","metadata":{"id":"102ef0a9-ce3e-4c75-a6e2-dfa02b3cc5e4"},"outputs":[],"source":["def param_hyperopt(train):\n","    \"\"\"\n","    模型参数搜索与优化函数\n","    :param train:训练数据集\n","    :return params_best:lgb最优参数\n","    \"\"\"\n","    \n","    # Part 1.划分特征名称，删除ID列和标签列\n","    label = \"target\"\n","    features = train.columns.tolist()\n","    features.remove(\"customer_ID\")\n","    features.remove(\"target\")\n","    \n","    # Part 2.封装训练数据\n","    train_data = lgb.Dataset(train[features], train[label])\n","    \n","    # Part 3.内部函数，输入模型超参数损失值输出函数\n","    def hyperopt_objective(params):\n","        \"\"\"\n","        输入超参数，输出对应损失值\n","        :param params:\n","        :return:最大自定义metric\n","        \"\"\"\n","        # 创建参数集\n","        params = params_append(params)\n","        print(f\"检查使用的LGBM参数：{params}\")\n","\n","        t = time.time() # 记录时间\n","        \n","        # 借助lgb的cv过程，输出某一组超参数下损失值的最小值\n","        res = lgb.cv(params, train_data, \n","                     num_boost_round = 3000,# 最大迭代次数 5000\n","                     nfold=5, # 交叉验证的次数（n折交叉验证）\n","                     stratified=True, # 不平衡数据\n","                     shuffle=True,\n","                     metrics=\"None\",\n","                     # early_stopping_rounds=500, #dart模式下面不需要early stopping\n","                     show_stdv=False,\n","                     seed=2022,\n","                     verbose_eval=500, # 1000\n","                     feval = lgb_amex_metric,\n","                     eval_train_metric=True,\n","                    )\n","        \n","        # 追踪记录\n","        dur = round((time.time() - t) / 60, 2)\n","        print(f\"本次贝叶斯优化evaluation的消耗时间 {dur} mins\")\n","        \n","        # 打印训练后的字典\n","        # print(f\"交叉验证后的结果字典：{res}\")\n","\n","        \n","        return -max(res[\"valid AMEX_metric-mean\"]) # 最大化自定义metric，但请注意我们在贝叶斯优化中的目标函数是最小化，所以要在前面加上负号\n","    \n","\n","    # Part 4.lgb超参数空间\n","    params_space = {\n","        'learning_rate': hp.uniform('learning_rate', 5e-3, 5e-1),\n","        'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n","        'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n","        'num_leaves': hp.choice('num_leaves', np.arange(30, 200, 10, dtype=int)),\n","        # 'reg_alpha': hp.randint('reg_alpha', 0, 10),\n","        # 'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n","        'bagging_freq': hp.randint('bagging_freq', 3, 13),\n","        'min_child_samples': hp.choice('min_child_samples', list(range(10, 50, 5))),\n","        'max_depth': hp.choice('max_depth', np.arange(5, 30, 3, dtype=int)),\n","    }\n","    \n","    # Part 5.TPE超参数搜索\n","    params_best = fmin( # 注意是最小化这个最优参数\n","        hyperopt_objective,\n","        space=params_space,\n","        algo=tpe.suggest,\n","        max_evals=30, # 50\n","        rstate=np.random.default_rng(2022)\n","    )\n","    \n","    # 天坑！必须要用space_eval处理！\n","    best_params=space_eval(params_space, params_best)\n","    \n","    # 返回最佳参数\n","    return params_best"]},{"cell_type":"markdown","id":"918eb7a9-00c7-46c7-9fca-90caf656b42b","metadata":{"id":"918eb7a9-00c7-46c7-9fca-90caf656b42b"},"source":["开始进行贝叶斯优化，求取最佳的超参数"]},{"cell_type":"code","execution_count":null,"id":"c860c2d6-9e32-4a4e-939b-a1eca83cab6d","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"c860c2d6-9e32-4a4e-939b-a1eca83cab6d","outputId":"7208d641-a6d0-4096-ad85-2ffca2c600e7","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["检查使用的LGBM参数：{'bagging_fraction': 0.7919796956560885, 'bagging_freq': 7, 'feature_fraction': 0.5728155231585855, 'learning_rate': 0.11142176050178165, 'max_depth': 5, 'min_child_samples': 35, 'num_leaves': 70, 'feature_pre_filter': False, 'objective': 'binary', 'metric': 'None', 'is_unbalance': True, 'boosting': 'dart', 'verbose': -1}\n","[500]\tcv_agg's train AMEX_metric: 0.815719\tcv_agg's valid AMEX_metric: 0.789643\n","[1000]\tcv_agg's train AMEX_metric: 0.835931\tcv_agg's valid AMEX_metric: 0.791827\n","[1500]\tcv_agg's train AMEX_metric: 0.853065\tcv_agg's valid AMEX_metric: 0.791435\n","[2000]\tcv_agg's train AMEX_metric: 0.870885\tcv_agg's valid AMEX_metric: 0.790698\n","[2500]\tcv_agg's train AMEX_metric: 0.889634\tcv_agg's valid AMEX_metric: 0.790933\n","[3000]\tcv_agg's train AMEX_metric: 0.904314\tcv_agg's valid AMEX_metric: 0.790236\n","本次贝叶斯优化evaluation的消耗时间 186.85 mins\n","检查使用的LGBM参数：{'bagging_fraction': 0.8450629040529597, 'bagging_freq': 10, 'feature_fraction': 0.8949698698614581, 'learning_rate': 0.3856699583843958, 'max_depth': 14, 'min_child_samples': 30, 'num_leaves': 120, 'feature_pre_filter': False, 'objective': 'binary', 'metric': 'None', 'is_unbalance': True, 'boosting': 'dart', 'verbose': -1}\n","[500]\tcv_agg's train AMEX_metric: 0.940069\tcv_agg's valid AMEX_metric: 0.74627\n","[1000]\tcv_agg's train AMEX_metric: 0.837315\tcv_agg's valid AMEX_metric: 0.649535\n","[1500]\tcv_agg's train AMEX_metric: 0.575627\tcv_agg's valid AMEX_metric: 0.507985\n","[2000]\tcv_agg's train AMEX_metric: 0.558158\tcv_agg's valid AMEX_metric: 0.502004\n","[2500]\tcv_agg's train AMEX_metric: 0.553781\tcv_agg's valid AMEX_metric: 0.502285\n","[3000]\tcv_agg's train AMEX_metric: 0.538543\tcv_agg's valid AMEX_metric: 0.488986\n","本次贝叶斯优化evaluation的消耗时间 269.72 mins\n","检查使用的LGBM参数：{'bagging_fraction': 0.7936532433431445, 'bagging_freq': 5, 'feature_fraction': 0.9188279098436349, 'learning_rate': 0.03318989544116032, 'max_depth': 20, 'min_child_samples': 45, 'num_leaves': 180, 'feature_pre_filter': False, 'objective': 'binary', 'metric': 'None', 'is_unbalance': True, 'boosting': 'dart', 'verbose': -1}\n","[500]\tcv_agg's train AMEX_metric: 0.82694\tcv_agg's valid AMEX_metric: 0.783756\n","[1000]\tcv_agg's train AMEX_metric: 0.872983\tcv_agg's valid AMEX_metric: 0.789435\n","[1500]\tcv_agg's train AMEX_metric: 0.916962\tcv_agg's valid AMEX_metric: 0.791609\n","[2000]\tcv_agg's train AMEX_metric: 0.957278\tcv_agg's valid AMEX_metric: 0.791642\n","[2500]\tcv_agg's train AMEX_metric: 0.986227\tcv_agg's valid AMEX_metric: 0.792146\n","  7%|▋         | 2/30 [14:04:12<109:56:42, 14135.82s/trial, best loss: -0.7922965886068797]"]}],"source":["best_clf = param_hyperopt(train_LGBM)"]},{"cell_type":"markdown","id":"2f411386","metadata":{"id":"2f411386"},"source":["### 输出最优参数"]},{"cell_type":"code","execution_count":null,"id":"db06186c-6815-4fe9-8920-ceb79ebebe4a","metadata":{"colab":{"background_save":true},"id":"db06186c-6815-4fe9-8920-ceb79ebebe4a"},"outputs":[],"source":["best_clf"]},{"cell_type":"markdown","id":"2825b4e5-02e6-46b2-978b-b979b57f9c58","metadata":{"id":"2825b4e5-02e6-46b2-978b-b979b57f9c58"},"source":["**请注意这里有一个天坑！！！** 我们必须在倒数第二行使用`space_eval(params_space, params_best)`\n","\n","如果不写，则直接输出`best_clf`是一个字典，这个东西看似是最优参数，其实不全是。如果你在搜索空间里设置的是**枚举类型(hp.choice)**，那么返回的是**索引**而不是真实值！\n","\n","有的时候会看见`num_leaves`为1，简直是匪夷所思。因为我在参数空间中根本没有设置过这样的数字。其实他是指你在参数空间中声明的可能值的那个数组的下标1对应的数字。"]},{"cell_type":"markdown","id":"86e89f4c","metadata":{"id":"86e89f4c"},"source":["因此我必须要利用`space_eval(参数空间, best_clf)`这个函数将返回的字典结果转化为装有最优参数的结果。"]},{"cell_type":"code","execution_count":null,"id":"fLxP6ogJRD9J","metadata":{"colab":{"background_save":true},"id":"fLxP6ogJRD9J"},"outputs":[],"source":["import pickle\n","with open(\"best_parameters.pkl\", \"wb\") as tf:\n","    pickle.dump(best_clf, tf)"]},{"cell_type":"markdown","id":"18e3847b","metadata":{"id":"18e3847b"},"source":["这样我们就得到了通过贝叶斯优化得到的最优超参数。\n","\n","通过这个最优超参数，我们可以在下面重新训练，并且结合交叉验证进行模型预测。"]},{"cell_type":"markdown","id":"6df04356","metadata":{"id":"6df04356"},"source":["## 训练模型"]},{"cell_type":"markdown","id":"3e369804-2018-47bf-862b-786a4166a8a3","metadata":{"id":"3e369804-2018-47bf-862b-786a4166a8a3"},"source":["### 利用交叉验证进行模型预测"]},{"cell_type":"markdown","id":"736cd447-b38e-4bb8-b057-9caa8b2a5a20","metadata":{"id":"736cd447-b38e-4bb8-b057-9caa8b2a5a20"},"source":["<center><img src=\"https://s2.loli.net/2021/12/08/ALF3cfuSwmB7b8z.png\" alt=\"image-20211208192640281\" style=\"zoom:33%;\" />"]},{"cell_type":"code","execution_count":null,"id":"a099a86f-f013-4d39-bd37-e4802e1e6342","metadata":{"colab":{"background_save":true},"id":"a099a86f-f013-4d39-bd37-e4802e1e6342"},"outputs":[],"source":["def train_predict(train, test, params):\n","    \"\"\"\n","    :param train:\n","    :param test:\n","    :param params:\n","    :return:\n","    \"\"\"\n","    print(\"*\"*50)\n","    print(\"LGBM 开始正式训练！\")\n","    print(\"*\"*50)\n","\n","    # Part 1.选择特征\n","    label = \"target\"\n","    features = train.columns.tolist()\n","    features.remove(\"customer_ID\")\n","    features.remove(\"target\")\n","\n","    print(f\"将要使用的LGBM的最优参数：{params}\")\n","\n","    # Part 2.申明固定参数与控制迭代参数\n","    params = params_append(params)\n","    ESR = 500\n","    NBR = 2000 # 10000训练模型可以调高\n","    VBE = 1000\n","\n","    # Part 3.创建结果存储容器\n","    # 测试集预测结果存储器，后保存至本地文件\n","    prediction_test = 0\n","    # 验证集的模型表现，作为展示用\n","    cv_score = []\n","    # 验证集的预测结果存储器，后保存至本地文件\n","    prediction_train = pd.Series()\n","\n","    # Part 3.交叉验证\n","    iteration = 1\n","    kf = StratifiedKFold(n_splits=5, random_state=2022, shuffle=True)\n","    for train_part_index, eval_index in kf.split(train[features], train[label]):\n","        print(\"*\"*30)\n","        print(f\"开始第{iteration}折的交叉验证！\")\n","        print(\"*\"*30)\n","        iteration += 1\n","\n","        t = time.time() # 记录时间\n","\n","        \n","        # 训练数据封装\n","        train_part = lgb.Dataset(\n","            train[features].loc[train_part_index],\n","            train[label].loc[train_part_index]\n","        )\n","        # 测试数据封装\n","        eval = lgb.Dataset(\n","            train[features].loc[eval_index],\n","            train[label].loc[eval_index]\n","        )\n","        # 依据验证集训练模型\n","        bst = lgb.train(\n","            params,\n","            train_part,\n","            num_boost_round=NBR,\n","            valid_sets=[train_part, eval],\n","            valid_names=['train', 'valid'],\n","            early_stopping_rounds=ESR,\n","            verbose_eval=VBE,   \n","            fdeval = lgb_amex_metric, # 自定义metric\n","        )\n","\n","        # 测试集预测结果并纳入prediction_test容器\n","        prediction_test += bst.predict(test[features])\n","        # 验证集预测结果并纳入prediction_train容器\n","        prediction_train = prediction_train.append(\n","            pd.Series(bst.predict(train[features].loc[eval_index]),index=eval_index))\n","        # 验证集预测结果\n","        eval_pre = bst.predict(train[features].loc[eval_index])\n","\n","        # 计算验证集上得分metric\n","        score = amex_metric(train[label].loc[eval_index].values, eval_pre)\n","\n","        # 纳入cv_score容器\n","        cv_score.append(score)\n","\n","        # 追踪记录\n","        dur = round((time.time() - t) / 60, 2)\n","        print(f\"第{iteration}个iteration训练所消耗的时间 {dur} mins\")\n","\n","\n","    print(\"*\"*50)\n","    print(\"LGBM 训练结束！开始保存结果！\")\n","    print(\"*\"*50)\n","        \n","    # Part 4.打印/输出结果\n","    # 打印验证集得分与平均得分\n","    print(f\"验证集得分：{cv_score}, 验证集平均分：{sum(cv_score)/5}\")\n","    \n","    # 将验证集上预测结果写入本地文件\n","    pd.Series(prediction_train.sort_index().values).to_csv(\"train_lightgbm.csv\", index=False)\n","    \n","    # 将测试集上预测结果写入本地文件\n","    pd.Series(prediction_test/5).to_csv(\"test_lightgbm.csv\", index=False)\n","    \n","    # 测试集平均得分作为模型最终预测结果\n","    test['target'] = prediction_test/5\n","    \n","    # 将测试集预测结果写成竞赛要求格式并保存至本地\n","    test[[\"customer_ID\", 'target']].to_csv(\"submission_lightgbm.csv\", index=False)\n","\n","    return"]},{"cell_type":"code","execution_count":null,"id":"b3fad7d3-0153-47c0-90ae-9d2eb1de06a2","metadata":{"colab":{"background_save":true},"id":"b3fad7d3-0153-47c0-90ae-9d2eb1de06a2","scrolled":false},"outputs":[],"source":["# best_clf = param_hyperopt(train_LGBM)\n","train_predict(train_LGBM, test_LGBM, best_clf)"]},{"cell_type":"code","execution_count":null,"id":"327a7dc3","metadata":{"colab":{"background_save":true},"id":"327a7dc3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4b225235","metadata":{"id":"4b225235"},"outputs":[],"source":[]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"3.2 LightGBM with Bayesian Optimisation.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"345.594px"},"toc_section_display":true,"toc_window_display":false},"vscode":{"interpreter":{"hash":"06e6f0634cef3c6b4c7215b86c5234fa5d208db2cad8fd7c34c132f10505d637"}}},"nbformat":4,"nbformat_minor":5}
