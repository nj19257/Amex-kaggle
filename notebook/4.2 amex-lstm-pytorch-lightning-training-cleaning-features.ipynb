{"cells":[{"cell_type":"markdown","metadata":{"id":"08cc1743"},"source":["# ⚡⚡ PyTorch Quickstart for the American Express - Default Prediction competition\n","This notebook shows how to define and train a Pytorch LSTM to leverages the time series structure of the data.\n","\n","I expect Deep Learning models to dominate in this competition, so here's a simple LSTM architecture.\n","\n","Parameters were not really tweaked so the baseline is improvable.\n","\n","**Please consider upvoting if you find this work helpful. Don't fork without upvoting !**\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1660972021881,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"HfXxLuH9sg_5","outputId":"677d2828-6570-45a3-aff3-aa2df1dab3bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Aug 20 05:07:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2780,"status":"ok","timestamp":1660972025551,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"SYaLHbDOBm4N","outputId":"209e257b-064e-4eb7-f842-1c74205fe2a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 把Google Drive挂载到Colab里\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except ImportError:\n","    pass"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660972025551,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"_vtFAOmwBm8E"},"outputs":[],"source":["# 修改当前文件夹位置 假定notebook文件就在项目文件夹根目录\n","import os\n","def get_root_dir():\n","    if os.path.exists('/content/drive/MyDrive/Colab/'):\n","        return '/content/drive/MyDrive/Colab/4-AMEX/AMEX Project/notebooks' #在Colab里\n","    else:\n","        return './' #在本地\n","\n","#调用系统命令，相当于cd，但是直接!cd是不行的\n","os.chdir(get_root_dir())\n","# %cd  .//drive/MyDrive/AMEX\\ Project/notebooks"]},{"cell_type":"markdown","metadata":{"id":"887d965e"},"source":["## Why PyTorch Lightning?\n","\n","Lightning is simply organized PyTorch code. There's NO new framework to learn. For more details about Lightning visit the repo:\n","\n","https://github.com/PyTorchLightning/pytorch-lightning\n","\n","Run on CPU, GPU clusters or TPU, without any code changes\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d4962c9d"},"source":["# Imports\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5664,"status":"ok","timestamp":1660972031212,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"MkEgT1LM8JSm","outputId":"d1ee35a1-a0cd-4014-b0e0-f90d2a2ae004"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.7.2)\n","Requirement already satisfied: tqdm\u003e=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Requirement already satisfied: PyYAML\u003e=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: packaging\u003e=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: tensorboard\u003e=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.10.0)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Requirement already satisfied: pyDeprecate\u003e=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.2)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,\u003e=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.7.1)\n","Requirement already satisfied: torchmetrics\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.9.3)\n","Requirement already satisfied: typing-extensions\u003e=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Requirement already satisfied: torch\u003e=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.1+cu113)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (3.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=17.0-\u003epytorch-lightning) (3.0.9)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.8.1)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.2.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (0.6.1)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.0.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (0.4.6)\n","Requirement already satisfied: protobuf\u003c3.20,\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (3.17.3)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (57.4.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (3.4.1)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.47.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.35.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (4.9)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.15.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (4.12.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (3.8.1)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (0.4.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (1.24.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.9.1-\u003epytorch-lightning) (3.2.0)\n","Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (2.1.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (0.13.0)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (1.8.1)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (1.3.1)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (4.0.2)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (22.1.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning) (6.0.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.1)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf\u003c4.0dev,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: GitPython\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: shortuuid\u003e=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.1.1)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.0.9)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython\u003e=1.0.0-\u003ewandb) (5.0.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Build  enviroment \n","%pip install pytorch-lightning\n","!pip install wandb\n","#login to tensorboard to save and \n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1660972031212,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"eaf16f4a"},"outputs":[],"source":["import pandas as pd\n","import gc\n","import numpy as np\n","\n","# Torch and Sklearn\n","import pytorch_lightning as pl\n","import torch\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchmetrics import Metric\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning import Trainer\n","import torch.nn.functional as F\n","from torch import nn, Tensor\n","from torchmetrics.utilities import rank_zero_warn\n","\n","# Typing \n","from typing import Optional"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"elapsed":6030,"status":"ok","timestamp":1660972037228,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"29QNRJSkKCEh","outputId":"f594c9d9-4559-4a5e-83a9-1606b39bb96f"},"outputs":[{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) =\u003e {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() =\u003e {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() =\u003e reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data =\u003e {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["To use your W\u0026B account,\n","Go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as WANDB. \n","Get your W\u0026B access token from here: https://wandb.ai/authorize\n"]}],"source":["import wandb\n","\n","try:\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    api_key = user_secrets.get_secret(\"WANDB\")\n","    wandb.login(key='6cc6eb507a318cfdf65bc1fee3cd6852e6c8e44c')     #This is my personal user id.\n","    anonymous = None\n","except:\n","    wandb.login(anonymous='must')\n","    print('To use your W\u0026B account,\\nGo to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as WANDB. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":3492,"status":"ok","timestamp":1660972040717,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"qmTfP4-PCB_V","outputId":"c30f3a55-025c-4cd1-cc4e-6fc8a5990759"},"outputs":[{"name":"stdout","output_type":"stream","text":["'1.1 EDA.ipynb'\n","'1.2.1 Fill missing values by RF (train set).ipynb'\n","'1.2.2 Fill missing values by RF (test set).ipynb'\n","'1.3 Data Processing Demo.ipynb'\n","'2.3.1 Feature Engineering-1.ipynb'\n","'2.3.2 Feature Engineering-2.ipynb'\n","'2.3.3 Feature Engineering-3.ipynb'\n","'2.3.4 Feature Engineering-4.ipynb'\n","'2.3.5 Feature Engineering-5.ipynb'\n","'2.3.6 Feature Engineering-6.ipynb'\n","'2.3.7 Feature Engineering-7.ipynb'\n","'2.3.8 Feature Engineering-8.ipynb'\n","'2.4 Interaction Feature Selection - Filter Method.ipynb'\n","'2.5 Wrapper Method.ipynb'\n","'3.2 LightGBM with Bayesian Optimisation.ipynb'\n","'3.6.1 MLP Bagging Training.ipynb'\n","'3.6.2 MLP Bagging Inference.ipynb'\n","'4.1 LSTM FE New.ipynb'\n","'4.2 amex-lstm-pytorch-lightning-training-cleaning-features.ipynb'\n","'4.3 amex-lstm-pytorch-lightning-inf-features.ipynb'\n","'4.4 amex-lstm-pytorch-lightning-inf-predict.ipynb'\n"," best_parameters.pkl\n"," build\n"," mycheckpoints\n"," submission_lightgbm.csv\n"," test_lightgbm.csv\n"," train_lightgbm.csv\n"," wandb\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-380572\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.1"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/wandb/run-20220820_050717-3jh17wk7\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/anony-moose-380572/AMEX/runs/3jh17wk7?apiKey=14badcc823ad5a59cc3248b0a73e8df423aa45ec\" target=\"_blank\"\u003esolar-haze-1\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/anony-moose-380572/AMEX?apiKey=14badcc823ad5a59cc3248b0a73e8df423aa45ec\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["!ls\n","from pytorch_lightning.loggers import WandbLogger\n","\n","wandb_logger = WandbLogger(project=\"AMEX\" ,log_model=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660972040717,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"4690198b"},"outputs":[],"source":["# File system\n","train_file   = \"../data/4-PreCompressed/FilledWithRandomForest/train_RandomForest(PreCompressed).parquet\"\n","train_labels = \"../data/1-original-data/train_labels.csv\"\n","model_output_folder = '../models/experiment'\n","\n","# Data\n","batch_size   = 256  #1028 to 512\n","# Number of GPU used - we only have access to one gpu , feels like num_workers = 1 will be the same\n","num_workers  = 4\n","epochs = 10\n","\n","# Model \n","# 輸入 x 的特徵數量\n","in_features=171\n","# 隱藏層 h 的特徵數量\n","hidden_dim=512      # 128 changed to 512\n","# LSTM 的循環層數 (Default=1)\n","num_layers=1  # 2 changed to 1\n","learning_rate=8e-3  # 1e-3 to 8e-3 or 1e-2\n","# bias: 若為 False，則 bias 初始化為 0 (Default=True)\n","# dropout: 若不為 0，則在每一層 LSTM 後都會接著 dropout (Default=0)\n","# bidirectional: 若為 True，則為雙向 LSTM (Default=False)"]},{"cell_type":"markdown","metadata":{"id":"d6c3c677"},"source":["# Data\n","\n","Reading and preprocessing the data\n","\n","We read the data from @raddar's [dataset](http://https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format) that i splitted into chunks [dataset](https://www.kaggle.com/datasets/what5up/amex-data-integer-dtypes-100k-cid-per-chunk). @raddar has denoised the data so that we can achieve better results with his dataset than with the original competition csv files.\n","\n","We also convert the dataframe into a 3D-tensor dataset as highlighted by Chris Deotte [here](https://www.kaggle.com/competitions/amex-default-prediction/discussion/327828) \n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660972040717,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"xoKH9yFw_IBW"},"outputs":[],"source":["# Function for de-noise\n","def de_noise(train_df):\n","  column_list = train_df.columns.tolist()\n","  column_list = column_list[2:]\n","  list_with_noise = []\n","  for x in range(0,188):\n","    if (train_df[column_list[x]].fillna(-9999) % 1  == 0).all() == False :\n","        list_with_noise.append(column_list[x])\n","  train_df[list_with_noise] -= 0.005\n","  train_df[list_with_noise] = train_df[list_with_noise].round(2)\n","  print(train_df)\n","  return train_df"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660972040717,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"Ypi3WWtuR0IJ","outputId":"ff0eb7f0-c9a3-43a3-8a55-c01b341b8157"},"outputs":[{"name":"stdout","output_type":"stream","text":["'1.1 EDA.ipynb'\n","'1.2.1 Fill missing values by RF (train set).ipynb'\n","'1.2.2 Fill missing values by RF (test set).ipynb'\n","'1.3 Data Processing Demo.ipynb'\n","'2.3.1 Feature Engineering-1.ipynb'\n","'2.3.2 Feature Engineering-2.ipynb'\n","'2.3.3 Feature Engineering-3.ipynb'\n","'2.3.4 Feature Engineering-4.ipynb'\n","'2.3.5 Feature Engineering-5.ipynb'\n","'2.3.6 Feature Engineering-6.ipynb'\n","'2.3.7 Feature Engineering-7.ipynb'\n","'2.3.8 Feature Engineering-8.ipynb'\n","'2.4 Interaction Feature Selection - Filter Method.ipynb'\n","'2.5 Wrapper Method.ipynb'\n","'3.2 LightGBM with Bayesian Optimisation.ipynb'\n","'3.6.1 MLP Bagging Training.ipynb'\n","'3.6.2 MLP Bagging Inference.ipynb'\n","'4.1 LSTM FE New.ipynb'\n","'4.2 amex-lstm-pytorch-lightning-training-cleaning-features.ipynb'\n","'4.3 amex-lstm-pytorch-lightning-inf-features.ipynb'\n","'4.4 amex-lstm-pytorch-lightning-inf-predict.ipynb'\n"," best_parameters.pkl\n"," build\n"," mycheckpoints\n"," submission_lightgbm.csv\n"," test_lightgbm.csv\n"," train_lightgbm.csv\n"," wandb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53559,"status":"ok","timestamp":1660972094274,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"f26a6a01","outputId":"1f4cd61a-41b3-4188-e6a7-4a876b8eb70d"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              customer_ID  target\n","0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n","1       00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n","2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n","3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n","4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0\n","...                                                   ...     ...\n","458908  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...       0\n","458909  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...       0\n","458910  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...       0\n","458911  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...       1\n","458912  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...       0\n","\n","[458913 rows x 2 columns]\n","                                               customer_ID        S_2  \\\n","0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-11-20   \n","12       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2018-03-13   \n","11       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2018-02-21   \n","10       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2018-01-11   \n","8        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-10-08   \n","...                                                    ...        ...   \n","5965857  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2017-10-20   \n","5965856  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2017-11-05   \n","5965867  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2017-08-09   \n","5965861  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2018-02-06   \n","5965868  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2018-03-14   \n","\n","              P_2  D_39       B_1       B_2       R_1       S_3  D_41  \\\n","0        0.950845   0.0  0.016888  1.003995  0.001789  0.102792   0.0   \n","12       0.934745   0.0  0.009382  1.007647  0.006104  0.135021   0.0   \n","11       0.937349   0.0  0.019837  1.008307  0.000607  0.102985   0.0   \n","10       0.909811   0.0  0.002829  1.004798  0.008175  0.098882   0.0   \n","8        0.914767   0.0  0.014324  1.000242  0.000263  0.108115   0.0   \n","...           ...   ...       ...       ...       ...       ...   ...   \n","5965857  0.979511   0.0  0.022695  0.557029  0.008897  0.091565   0.0   \n","5965856  0.979333  14.0  0.020818  0.828199  0.003487  0.090743   0.0   \n","5965867  0.968892  19.0  0.034385  0.435834  0.000037  0.028395   0.0   \n","5965861  0.969861  15.0  0.009855  1.003541  0.005117  0.101802   0.0   \n","5965868  0.982175   0.0  0.000077  0.992880  0.000809  0.119165   0.0   \n","\n","              B_3  ...  D_136  D_137  D_138  D_139  D_140  D_141  D_143  \\\n","0        0.009817  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","12       0.007174  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","11       0.007454  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","10       0.003238  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","8        0.007836  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","...           ...  ...    ...    ...    ...    ...    ...    ...    ...   \n","5965857  0.045471  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","5965856  0.025139  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","5965867  0.044833  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","5965861  0.008578  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","5965868  0.014092  ...   -1.0   -1.0   -1.0    0.0    0.0    0.0    0.0   \n","\n","            D_144  D_145  target  \n","0        0.004369    0.0       0  \n","12       0.002970    0.0       0  \n","11       0.006346    0.0       0  \n","10       0.003004    0.0       0  \n","8        0.009616    0.0       0  \n","...           ...    ...     ...  \n","5965857  0.003811    0.0       0  \n","5965856  0.001498    0.0       0  \n","5965867  0.008519    0.0       0  \n","5965861  0.001168    0.0       0  \n","5965868  0.003184    0.0       0  \n","\n","[5965869 rows x 174 columns]\n"]}],"source":["def load_train_df(train_file, train_labels , labelled = True): # edited labelled \n","  # The original input data have split to 5 with only 400mb each(mentioned it have been denoised) .Not sure how they do it \n","  # Not enough Ram as the data feed in is too big\n","    train = pd.read_parquet(train_file)\n","    # Specify S_2 is the data for time\n","    train['S_2'] = pd.to_datetime(train['S_2'])\n","    tmp = train[['customer_ID','S_2']].groupby('customer_ID').count()\n","\n","    missing_cids = []\n","    for nb_available_rows in range(1, 14):\n","        cids = tmp[tmp['S_2'] == nb_available_rows].index.values\n","        batch_missing_cids = [cid for cid in cids for _ in range(13 - nb_available_rows)]\n","        missing_cids.extend(batch_missing_cids)\n","\n","    train_part2 = train.iloc[:len(missing_cids)].copy()\n","    train_part2.loc[:] = np.nan\n","    train_part2['customer_ID'] = missing_cids\n","\n","    train = pd.concat([train_part2, train])\n","    \n","    train = train.sort_values('customer_ID')\n","    # if , else is added\n","    if labelled == True:\n","      train_labels = pd.read_csv(train_labels)\n","      print(train_labels)\n","    else:\n","      df_etrain_labels = pd.DataFrame({'target' : []})\n","    train = pd.merge(train, train_labels, how='inner', on='customer_ID')\n","    \n","    train = train.sort_values('customer_ID')\n","    return train\n","\n","train_df = load_train_df(train_file, train_labels)\n","print(train_df)\n","#train_df = de_noise(train_df)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1660972094274,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"yDJjV85SCyR0","outputId":"eacbe503-d1d3-4c06-ecd8-ee81f26d8447"},"outputs":[{"name":"stdout","output_type":"stream","text":["Is the GPU available? True\n"]}],"source":["#print(train_df.head())\n","gpu_avail = torch.cuda.is_available()\n","print(f\"Is the GPU available? {gpu_avail}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660972094274,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"a03d07f0"},"outputs":[],"source":["class DataModule(pl.LightningDataModule):\n","    # \n","    def __init__(self, all_data: pd.DataFrame, batch_size: int = batch_size, num_workers: int = num_workers):\n","        super().__init__()\n","        self.all_data = all_data\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","        self.sc = StandardScaler()\n","\n","    def prepare_data(self):\n","        pass\n","\n","    def setup(self, stage=None):\n","        # All data comumns except customer_ID, target, and S_2 are features\n","        features = self.all_data.columns[2:-1]\n","        self.all_data[features] = self.sc.fit_transform(self.all_data[features])\n","        self.all_data[features] = self.all_data[features].fillna(0)\n","        \n","        # https://www.kaggle.com/competitions/amex-default-prediction/discussion/327828 !! Many Thanks @Chris Deotte for your sharing\n","        all_tensor_x = torch.reshape(torch.tensor(self.all_data[features].to_numpy()), (-1, 13, 171)).float()\n","        all_tensor_y = torch.tensor(self.all_data.groupby('customer_ID').first()['target'].to_numpy()).float()\n","        #Split data Test and Train data\n","        X_trainval, X_test, y_trainval, y_test = train_test_split(all_tensor_x, all_tensor_y, test_size=0.1, random_state=1)\n","        # Data Train(X_trainval, y_trainval) ; Data Test( X_test, y_test)\n","        X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, random_state=1)\n","\n","        # TRAIN\n","        self.train_tensor = TensorDataset(X_train, y_train)\n","        # VAL\n","        self.val_tensor = TensorDataset(X_val, y_val)\n","        # TEST\n","        self.test_tensor = TensorDataset(X_test, y_test)\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train_tensor, batch_size=self.batch_size, num_workers=self.num_workers)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.val_tensor, batch_size=self.batch_size, num_workers=self.num_workers)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.test_tensor, batch_size=self.batch_size, num_workers=self.num_workers)\n","    # Added\n","    def predict_dataloader(self):\n","        return DataLoader(self.test_tensor, batch_size=self.batch_size, num_workers=self.num_workers)"]},{"cell_type":"markdown","metadata":{"id":"758fd9df"},"source":["# Metrics : [Implementation Source](https://www.kaggle.com/code/rohanrao/amex-competition-metric-implementations)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660972094274,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"11f6e3f7"},"outputs":[],"source":["## https://www.kaggle.com/code/rohanrao/amex-competition-metric-implementations\n","\n","class AmexMetric(Metric):\n","    is_differentiable: Optional[bool] = False\n","\n","    # Set to True if the metric reaches it optimal value when the metric is maximized.\n","    # Set to False if it when the metric is minimized.\n","    higher_is_better: Optional[bool] = True\n","\n","    # Set to True if the metric during 'update' requires access to the global metric\n","    # state for its calculations. If not, setting this to False indicates that all\n","    # batch states are independent and we will optimize the runtime of 'forward'\n","    full_state_update: bool = True\n","\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.add_state(\"all_true\", default=[], dist_reduce_fx=\"cat\")\n","        self.add_state(\"all_pred\", default=[], dist_reduce_fx=\"cat\")\n","\n","        rank_zero_warn(\n","            \"Metric `Amex` will save all targets and predictions in buffer.\"\n","            \" For large datasets this may lead to large memory footprint.\"\n","        )\n","\n","    def update(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n","        \n","        y_true = y_true.double()\n","        y_pred = y_pred.double()\n","        \n","        self.all_true.append(y_true)\n","        self.all_pred.append(y_pred)\n","        \n","    def compute(self):\n","        y_true = torch.cat(self.all_true)\n","        y_pred = torch.cat(self.all_pred)\n","        # count of positives and negatives\n","        n_pos = y_true.sum()\n","        n_neg = y_pred.shape[0] - n_pos\n","\n","        # sorting by descring prediction values\n","        indices = torch.argsort(y_pred, dim=0, descending=True)\n","        preds, target = y_pred[indices], y_true[indices]\n","\n","        # filter the top 4% by cumulative row weights\n","        weight = 20.0 - target * 19.0\n","        cum_norm_weight = (weight / weight.sum()).cumsum(dim=0)\n","        four_pct_filter = cum_norm_weight \u003c= 0.04\n","\n","        # default rate captured at 4%\n","        d = target[four_pct_filter].sum() / n_pos\n","\n","        # weighted gini coefficient\n","        lorentz = (target / n_pos).cumsum(dim=0)\n","        gini = ((lorentz - cum_norm_weight) * weight).sum()\n","\n","        # max weighted gini coefficient\n","        gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n","\n","        # normalized weighted gini coefficient\n","        g = gini / gini_max\n","        \n","        return 0.5 * (g + d)\n","\n","\n","def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -\u003e float:\n","    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -\u003e float:\n","        df = (pd.concat([y_true, y_pred], axis='columns')\n","              .sort_values('prediction', ascending=False))\n","        df['weight'] = df['target'].apply(lambda x: 20 if x == 0 else 1)\n","        four_pct_cutoff = int(0.04 * df['weight'].sum())\n","        df['weight_cumsum'] = df['weight'].cumsum()\n","        df_cutoff = df.loc[df['weight_cumsum'] \u003c= four_pct_cutoff]\n","        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n","\n","    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -\u003e float:\n","        df = (pd.concat([y_true, y_pred], axis='columns')\n","              .sort_values('prediction', ascending=False))\n","        df['weight'] = df['target'].apply(lambda x: 20 if x == 0 else 1)\n","        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n","        total_pos = (df['target'] * df['weight']).sum()\n","        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n","        df['lorentz'] = df['cum_pos_found'] / total_pos\n","        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n","        return df['gini'].sum()\n","\n","    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -\u003e float:\n","        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n","        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n","\n","    g = normalized_weighted_gini(y_true, y_pred)\n","    d = top_four_percent_captured(y_true, y_pred)\n","\n","    return 0.5 * (g + d)"]},{"cell_type":"markdown","metadata":{"id":"823f8f67"},"source":["## Model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660972094276,"user":{"displayName":"Henry Yuan He","userId":"02022249127469846251"},"user_tz":-480},"id":"ab92c785"},"outputs":[],"source":["class LSTMClassifier(nn.Module):\n","    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n","\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, device):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        #全连接层的输入\n","        self.fc1 = nn.Linear(hidden_dim, 100)\n","        #全连接层的输出\n","        self.fc2 = nn.Linear(100, output_dim)\n","        print('test')\n","        ### Test - 全连接层的输入与输出\n","        #self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.device = device\n","\n","    def forward(self, x):\n","        h0, c0 = self.init_hidden(x)         #????\n","        out, (_, _) = self.rnn(x, (h0, c0))  #????\n","        out = F.relu(self.fc1(out[:, -1, :]))\n","        #Any real value is taken in where the value is reduced between 0 and 1\n","        out = torch.sigmoid(self.fc2(out))\n","        return out\n","\n","    def init_hidden(self, x):\n","        batch_size = x.size(0)\n","        #返回一个形状为为size,类型为torch.dtype，里面的每一个值都是0的tensor\n","        # The input of this function is a 3x3 size number\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n","        if torch.cuda.is_available():\n","            h0, c0 = h0.cuda(), c0.cuda()\n","        return h0, c0\n","\n","\n","class TsLstmLightning(pl.LightningModule):\n","    def __init__(self, in_features, hidden_dim, num_layers, learning_rate):\n","        super(TsLstmLightning, self).__init__()\n","\n","        self.learning_rate = learning_rate\n","\n","        self.train_amex_metric = AmexMetric()\n","        self.val_amex_metric   = AmexMetric()\n","        self.test_amex_metric = AmexMetric()    #Added\n","\n","        self.model = LSTMClassifier(in_features, hidden_dim, num_layers, 1, device = self.device)\n","\n","        self.num_parameters = count_parameters(self.model)\n","        \n","        print(f\"Trainable params: {self.num_parameters:,}\")\n","\n","        self.loss_fn = nn.BCELoss(reduction=\"mean\")\n","\n","    def forward(self, x):\n","        res = self.model(x)\n","        return res\n","\n","    def training_step(self, batch, batch_idx):\n","        X, target = batch\n","        preds = self(X)  # (batch_size, 1)\n","        preds = preds.squeeze(1)\n","\n","        loss = self.loss_fn(preds, target)\n","        \n","        self.train_amex_metric.update(preds, target) \n","\n","        self.log_dict({'train_loss': loss, 'train_amex_metric': self.train_amex_metric }, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","\n","        return {'loss': loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        with torch.no_grad():\n","            X, target = batch\n","            preds = self(X)  \n","            preds = preds.squeeze(1)\n","\n","            loss = self.loss_fn(preds, target)\n","            \n","            self.val_amex_metric.update(preds, target),\n","\n","            self.log_dict({'val_loss': loss, 'val_amex_metric': self.val_amex_metric}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","\n","            return {'loss': loss}\n","# Start added test_step - testing\n","    def test_step(self, batch, batch_idx):\n","        with torch.no_grad():\n","            X, target = batch\n","            preds = self(X)  \n","            preds = preds.squeeze(1)\n","\n","            loss = self.loss_fn(preds, target)\n","            \n","            self.test_amex_metric.update(preds, target),\n","\n","            self.log_dict({'test_loss': loss, 'test_amex_metric': self.test_amex_metric}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","\n","            return {'loss': loss}\n","#End\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        with torch.no_grad():\n","            X = batch[0]\n","            preds = self(X)\n","            return preds.detach().cpu()\n","\n","    def configure_optimizers(self):\n","      #Using adam optimiser\n","      #As Adma is so far the most optimiser\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n","        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n","        return [optimizer], [lr_scheduler]\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"30a6dd28"},"source":["# Training Loop "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5ac24279"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Shape: (5965869, 174)\n","test\n","Trainable params: 1,454,281\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `Amex` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n","  warnings.warn(*args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n","  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name              | Type           | Params\n","-----------------------------------------------------\n","0 | train_amex_metric | AmexMetric     | 0     \n","1 | val_amex_metric   | AmexMetric     | 0     \n","2 | test_amex_metric  | AmexMetric     | 0     \n","3 | model             | LSTMClassifier | 1.5 M \n","4 | loss_fn           | BCELoss        | 0     \n","-----------------------------------------------------\n","1.5 M     Trainable params\n","0         Non-trainable params\n","1.5 M     Total params\n","5.817     Total estimated model params size (MB)\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.020953893661499023,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Sanity Checking","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"c43e2362e7a1497f9b2ed0d24100afe3","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.020540952682495117,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Training","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"38c2931945994d76a16da9c5fe3ecbdd","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.02189779281616211,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"e0321aa2edfb4ea08149f9df370a14c2","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 1453: 'val_loss_epoch' reached 0.24311 (best 0.24311), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=0-step=1453.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.022181987762451172,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"c4db51a5c63b448ab2ad2e3ce7715169","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 2906: 'val_loss_epoch' reached 0.23932 (best 0.23932), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=1-step=2906.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.021785974502563477,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"fa56ab3d923840699b1374a797d2e805","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 4359: 'val_loss_epoch' reached 0.23923 (best 0.23923), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=2-step=4359.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.021132707595825195,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"4ca1f37fa5cd4aa8a3caa4a2296a7c56","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 5812: 'val_loss_epoch' reached 0.23798 (best 0.23798), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=3-step=5812.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.021976470947265625,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"90e1debff3a24c7e8d22ff59cf77943a","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 7265: 'val_loss_epoch' reached 0.23790 (best 0.23790), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=4-step=7265.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.02332782745361328,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"49b71ca3083b4d7b996c471cb38104fa","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 8718: 'val_loss_epoch' reached 0.23789 (best 0.23789), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=5-step=8718.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.021466970443725586,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"67ea3bd62fb74292bbbf82920a550bd7","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 10171: 'val_loss_epoch' reached 0.23789 (best 0.23789), saving model to '/content/drive/.shortcut-targets-by-id/1-6G5JjzxCCkstqGX9WjENeODam918ybc/4-AMEX/AMEX Project/notebooks/mycheckpoints/epoch=6-step=10171.ckpt' as top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.020945072174072266,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"94dfb82560f94641b5080644ca456fa0","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 11624: 'val_loss_epoch' was not in top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.022979259490966797,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"592a0ca9b6e247b4a7c07bff0c23644d","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 13077: 'val_loss_epoch' was not in top 1\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.022270917892456055,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Validation","rate":null,"total":null,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"fdb5175e87284dea9d6828247a7779c4","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 14530: 'val_loss_epoch' was not in top 1\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"]}],"source":["print(f\"Train Shape: {train_df.shape}\")\n","dm = DataModule(train_df, batch_size=batch_size)\n","\n","model = TsLstmLightning(in_features=in_features, hidden_dim=hidden_dim, num_layers=num_layers, learning_rate=learning_rate)\n","\n","#logger = TensorBoardLogger(model_output_folder, name=f\"logs\", default_hp_metric=True)\n","\n","#checkpoint_callback = ModelCheckpoint(dirpath= \"mycheckpoints\", save_top_k=1, save_weights_only=True, save_last=False, verbose=True,\n","#                                      monitor='val_loss_epoch', mode='min')\n","\n","checkpoint_callback = ModelCheckpoint(dirpath= \"mycheckpoints\", save_weights_only=True, save_last=True, verbose=True,\n","                                      monitor='val_loss_epoch', mode='min')\n","callbacks = [checkpoint_callback]\n","\n","trainer = Trainer(\n","    gpus=[0] if torch.cuda.is_available() else None,\n","    max_epochs=epochs,\n","    benchmark=False,\n","    deterministic=True,\n","    callbacks=callbacks,\n","    logger= wandb_logger)\n","\n","trainer.fit(model, dm)\n","#trainer.summary()\n","# For enable a test loop, test_step will be needed in TsLstmLightning()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xR284r7hE4zI"},"outputs":[{"name":"stdout","output_type":"stream","text":["'1.1 EDA.ipynb'\n","'1.2.1 Fill missing values by RF (train set).ipynb'\n","'1.2.2 Fill missing values by RF (test set).ipynb'\n","'1.3 Data Processing Demo.ipynb'\n","'2.3.1 Feature Engineering-1.ipynb'\n","'2.3.2 Feature Engineering-2.ipynb'\n","'2.3.3 Feature Engineering-3.ipynb'\n","'2.3.4 Feature Engineering-4.ipynb'\n","'2.3.5 Feature Engineering-5.ipynb'\n","'2.3.6 Feature Engineering-6.ipynb'\n","'2.3.7 Feature Engineering-7.ipynb'\n","'2.3.8 Feature Engineering-8.ipynb'\n","'2.4 Interaction Feature Selection - Filter Method.ipynb'\n","'2.5 Wrapper Method.ipynb'\n","'3.2 LightGBM with Bayesian Optimisation.ipynb'\n","'3.6.1 MLP Bagging Training.ipynb'\n","'3.6.2 MLP Bagging Inference.ipynb'\n","'4.1 LSTM FE New.ipynb'\n","'4.2 amex-lstm-pytorch-lightning-training-cleaning-features.ipynb'\n","'4.3 amex-lstm-pytorch-lightning-inf-features.ipynb'\n","'4.4 amex-lstm-pytorch-lightning-inf-predict.ipynb'\n"," best_parameters.pkl\n"," build\n"," mycheckpoints\n"," submission_lightgbm.csv\n"," test_lightgbm.csv\n"," train_lightgbm.csv\n"," wandb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ccdd4d03"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"2d3289a3"},"source":["# Train Monitoring\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"c0c0292d"},"outputs":[],"source":["#Using wandb now"]},{"cell_type":"markdown","metadata":{"id":"4d85e763"},"source":["# Possible Nexts steps\n","\n","\n","1. Have a best handling of missiing values in the data ( Ex : Do not drop customers that don't have 13 records,  do not fill N/A with 0, Replace previous -1 values with N/A, ...)\n","2. Enhance the model (More LSTM / 1D CNN / Transformers / Param optimisation / ... ) \n","3. Have a better understanding of the predictive features = Feature engineering ( feature selection or permutation feature importance, for instance.)\n","4. (1. + 2.--\u003e Transformer Unsupervised training with Times Series) https://arxiv.org/abs/2010.02803\n","5. Model ensemble with other classification techniques\n","6. Enable Cross-validation (Stratified K-Fold, ...)\n"]},{"cell_type":"markdown","metadata":{"id":"Wt8LaMeUjdLC"},"source":["## TO DO\n","\n","Getting confused with the format of dataset feed in the model\n","\n","*   Getting confused with the format of dataset feed in the model (using MNIST()function and utils.data.DataLoader()???)\n","*   Need to add in predict_dataloader() in the TsLstmLightning() ?\n","*   Use tuner() for part of hyperparameter tuning \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"khIjRm3dX02D"},"outputs":[],"source":["# default used by the Trainer\n","#trainer = Trainer(weights_save_path=os.getcwd())\n","\n","# save to your custom path\n","#trainer = Trainer(weights_save_path=\"my/path\")\n","\n","# Using wandb to store weight\n","#def predict_data():\n","#  predict_df = \n","#  features = self.all_data.columns[2:-1]\n","#  self.all_data[features] = self.sc.fit_transform(self.all_data[features])\n","#  self.all_data[features] = self.all_data[features].fillna(0)\n","#        \n","  # https://www.kaggle.com/competitions/amex-default-prediction/discussion/327828 !! Many Thanks @Chris Deotte for your sharing\n","#  all_tensor_x = torch.reshape(torch.tensor(self.all_data[features].to_numpy()), (-1, 13, 188)).float()\n","#  all_tensor_y = torch.tensor(self.all_data.groupby('customer_ID').first()['target'].to_numpy()).float()\n","\n","#trainer.test(datamodule=dm)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2IU44zrhisI7"},"outputs":[],"source":["#test_file   = \"./input/amex-data-integer-dtypes-100k-cid-per-chunk/train_chunk_0.parquet\"\n","#test_df = pd.read_parquet(test_file)\n","#model.eval()\n","#dm_predict = DataModule(test_df, batch_size=batch_size)\n","#data_loader = DataLoader(test_df)\n","##predictions = trainer.predict(model, data_loader)\n","#trainer.test(datamodule=dm_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3ed46747"},"outputs":[],"source":["#test_file   = \"./input/amex-data-integer-dtypes-100k-cid-per-chunk/test_chunk_0.parquet\"\n","#test_df = pd.read_parquet(test_file)\n","#test_df['target']= np.zeros\n","#print(len(test_df))\n","#print(test_df.head())\n","#print(torch.from_numpy(test_df).type(torch.Tensor))\n","#trainer.predict(test_df)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"4.2 amex-lstm-pytorch-lightning-training-cleaning-features.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":276.036446,"end_time":"2022-06-24T12:40:59.397074","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-06-24T12:36:23.360628","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}